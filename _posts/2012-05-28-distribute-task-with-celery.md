---
layout: entry
title: Celery를 이용한 긴 작업 처리
author: 문성원
author-email: longfin@spoqa.com
description: 처리 시간이 오래 걸리는 작업을 Celery를 통해 개선하는 방법을 알아봅니다.
---

스포카 개발팀 문성원입니다. 오늘은 [Celery]를 통해 오랜 시간이 걸리는 작업을 어떻게 개선하는지를 실례를 통해 알아보겠습니다.

# Why Celery?

지난주에 저희는 대량의 [PDF]파일을 만들어서 관리자용 웹 페이지를 통해 다운로드 받게끔 하는 기능을 추가해야 했습니다. 기존에 이미지파일을 압축해서 [HTTP] 응답으로 내려주던 핸들러가 있었기에, 압축 루틴을 [PDF] 생성 루틴으로 바꿔치기만 하면 되는 아주 간단한 일이라고 생각했죠.(실제로 저희팀의 [유병석]님이 [reportlab]과 [pyfpdf]를 사용해서 멋지게 구현하셨죠.)  이렇게 말입니다.

src1

그런데 문제가 생겼습니다. 이미지를 압축해서 내려주는 것에 비해서 [PDF]를 만드는데는 훨씬 많은 시간이 필요했고, 이 때문에 사용하던 서비스([Heroku])에서 타임아웃을 내버렸습니다. 요청을 처리하는 핸들러가 직접 파일을 만들어서 줄 수 없게 되버렸습니다.

다행히 저희는 이런 문제에 대한 일반적인 해결책을 잘 알고 있었습니다. 바로 별도의 작업자(Worker)를 두는 것이지요. 시간이 오래 걸리는 [PDF] 생성 루틴은 웹서버와 별개로 돌아가는 작업자에게 위임하고 요청을 처리하는 핸들러는 클라이언트(웹브라우저)에게 바로 [HTTP] 응답을 돌려줍니다. 생성된 파일은 [S3]에 업로드해서 완료될때 요청자가 다운로드 받을 수 있게 만들면 되구요.

img1

그럼 이러한 작업자는 어떻게 구현할까요? 물론 시간과 여유가 있으신 분들은 바닥부터 만들어보시는 것도 좋은 경험이겠습니다만, 저희는 그럴 시간은 없었습니다. 그래서 선택한 것이 [Celery]입니다. [지난 포스팅]에서 인용한 [Celery]에 관한 소개를 보시죠.

[Celery]는 [Python]으로 작성된 **비동기 작업 큐(Asynchronous task queue/job queue)**입니다. 앞서 소개한 **작업(Task)**를 **브로커(Broker, 스포카 서버는 [Redis]를 사용)**를 통해 전달하면 하나 이상의 **워커(Worker)**가 이를 처리하는 구조입니다. 포인트 적립-공유에 따른 분배처리, 포스팅 기능, 페이스북/트위터 공유등의 비동기 처리가 필요한 작업을 [Celery]에 위임하여 처리하고 있습니다.

이 시나리오에서 작업(Task)에 해당하는 것은 [PDF] 생성후 업로드입니다. 이 작업을 브로커(Broker)에 넣는 것은 요청을 받은 핸들러겠구요. 한번 고쳐진 소스를 보실까요?

src2

# Not enuogh memery

자 이제 응답이 지연될 일도 없으니 다 되었다고 생각한 저희는 테스트 환경에 배포해보았습니다. 그런데 테스트 중 이상한 에러 메시지가 떴습니다.

src3

[R14 에러]에 대한 설명을 살펴보니 아무래도 [PDF]를 만드는 도중 메모리가 부족해진 것 같네요. 실제로 [Heroku]의 [Dyno]의 메모리 상한은 고작 512MB입니다. 하지만 우리가 만들 [PDF]생산 로직은 1000 페이지당 약 1G정도를 사용합니다. 

이때 ([김재석)님이) 제기된 방법이 페이지를 분할해서 저장하는 것입니다. [Dyno]가 감당할 수 있을만큼의 페이지 단위의 작업으로 쪼갠 뒤에 다시 큐에 넣어 각기 다른 작업자가 처리하게 하는 것이죠.(물론 [Dyno]당 메모리 제한이기떄문에 [Celery]의 [concurreny]를 고려해야합니다.) 

img2

코드에 적용해볼까요?

src4

단 이 코드는 [데드락을 유발 시킬 수 있습니다.] 작업 내에서 다른 작업 때문에 대기하고 있는 것은 큐라는 자원을 공유하는 이상 위험하기 때문이죠. 때문에 [Celery]는 이런 작업을 지원하기 위해 [chord]라는 별도의 개념을 도입했습니다. [chord]는 [subtask]들의 집합으로 묶여있는 작업들과, 그 작업들이 모두 끝났을때 불릴 콜백(Callback)으로 구성됩니다. 이 [chord]를 통해 원래 코드를 수정하면 다음과 같습니다.

src5

# Save money

이제 적절한 수의 작업자를 [Procfile]에 설정해서 올리기만 하면 됩니다. 그런데 여기서 한가지 아쉬운 점이 있습니다. 대량의 [PDF]를 처리하는 일은 그리 빈번히 발생하는 일이 아니기 때문에 이를 기준으로 작업자수를 설정하면 그만큼 노는 작업자가 늘게 됩니다. 작업자 [Dyno]수에 따라 과금되는 [Heroku]를 사용하고 있는 저희로서는 피하고 싶은 일이죠. 그래서 작업할때만 작업자를 명시적으로 확장(Scale Up)하고, 작업이 끝나면 줄이는(Scale Down) 할 수 있는 방법이 필요했습니다. 이 때 필요한 것이 바로 [heroku.py]입니다. [heroku.py]는 [Heroku]의 [HTTP API]를 [Python]에서 사용할 수 있도록 싸놓은 인터페이스입니다. 이러한 [heroku.py]를 이용해서 작업자를 조정하는 메서드를 간단히 정의해볼까요?

src6


마지막으로 이를 적용한 최종적인 코드는 다음과 같습니다.

src7
